"""
Module ƒë·ªÉ t·∫°o bi·ªÉu ƒë·ªì ph√¢n t√≠ch OCR t·ª´ file JSON comparison report
"""

import json
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from math import pi
import os

# Thi·∫øt l·∫≠p matplotlib ƒë·ªÉ tr√°nh l·ªói GUI
import matplotlib
matplotlib.use('Agg')

class JSONOCRVisualizationTool:
    def __init__(self):
        """Kh·ªüi t·∫°o JSON OCR Visualization Tool"""
        print("üìä Kh·ªüi t·∫°o JSON OCR Visualization Tool...")
        
        # Thi·∫øt l·∫≠p ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c (t·ª´ Demo l√™n DACN)
        self.base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.results_dir = os.path.join(self.base_dir, "Results")
        self.json_dir = os.path.join(self.results_dir, "Json")
        self.charts_dir = os.path.join(self.results_dir, "Charts")
        
        # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a t·ªìn t·∫°i
        os.makedirs(self.json_dir, exist_ok=True)
        os.makedirs(self.charts_dir, exist_ok=True)
        
        # Thi·∫øt l·∫≠p style
        plt.style.use('default')
        sns.set_palette("husl")
        
        # M√†u s·∫Øc cho c√°c engine
        self.engine_colors = {
            'easyocr': '#3498db',           # Blue
            'easyocr_preprocessed': '#5dade2',  # Light Blue
            'doctr': '#e74c3c',             # Red
            'doctr_preprocessed': '#ec7063',    # Light Red
            'pytesseract': '#f39c12',       # Orange
            'pytesseract_preprocessed': '#f7dc6f',  # Light Orange
            'opencv': '#27ae60'             # Green
        }
        
        print(f"üìÇ Th∆∞ m·ª•c JSON: {self.json_dir}")
        print(f"üìä Th∆∞ m·ª•c Charts: {self.charts_dir}")
        print("‚úÖ JSON OCR Visualization Tool ƒë√£ s·∫µn s√†ng!")
    
    def load_comparison_data(self, json_file_path):
        """ƒê·ªçc d·ªØ li·ªáu t·ª´ file JSON comparison report"""
        try:
            # N·∫øu ch·ªâ l√† t√™n file, t√¨m trong th∆∞ m·ª•c Json
            if not os.path.isabs(json_file_path):
                json_file_path = os.path.join(self.json_dir, json_file_path)
            
            with open(json_file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            print(f"‚úÖ ƒê√£ ƒë·ªçc d·ªØ li·ªáu t·ª´: {json_file_path}")
            return data
        except Exception as e:
            print(f"‚ùå L·ªói ƒë·ªçc file JSON: {str(e)}")
            return None
    
    def filter_engines_with_data(self, data, require_confidence=True, require_words=True):
        """L·ªçc c√°c engine c√≥ ƒë·ªß d·ªØ li·ªáu c·∫ßn thi·∫øt"""
        filtered_engines = {}
        
        for engine_key, engine_data in data.get('engines', {}).items():
            # Ki·ªÉm tra d·ªØ li·ªáu c∆° b·∫£n
            has_time = engine_data.get('avg_processing_time', 0) > 0 or engine_data.get('avg_time', 0) > 0
            has_words = engine_data.get('avg_word_count', 0) > 0 or engine_data.get('avg_words', 0) > 0
            has_confidence = 'avg_confidence' in engine_data and engine_data.get('avg_confidence', 0) > 0
            
            # OpenCV ch·ªâ c√≥ time, kh√¥ng c√≥ confidence v√† word count th·ª±c s·ª±
            is_opencv = 'opencv' in engine_key.lower()
            
            # ƒêi·ªÅu ki·ªán l·ªçc
            if not has_time:
                continue
                
            if require_confidence and not has_confidence and not is_opencv:
                continue
                
            if require_words and not has_words and not is_opencv:
                continue
            
            # Chu·∫©n h√≥a t√™n tr∆∞·ªùng ƒë·ªÉ t∆∞∆°ng th√≠ch
            normalized_data = dict(engine_data)
            if 'avg_time' in engine_data and 'avg_processing_time' not in engine_data:
                normalized_data['avg_processing_time'] = engine_data['avg_time']
            if 'avg_words' in engine_data and 'avg_word_count' not in engine_data:
                normalized_data['avg_word_count'] = engine_data['avg_words']
                
            filtered_engines[engine_key] = normalized_data
        
        return filtered_engines
    
    def create_grouped_bar_chart_from_json(self, json_file_path, output_filename="grouped_bar_chart"):
        """T·∫°o bi·ªÉu ƒë·ªì c·ªôt nh√≥m t·ª´ file JSON"""
        print(f"üìä T·∫°o bi·ªÉu ƒë·ªì c·ªôt nh√≥m t·ª´ {json_file_path}...")
        
        # ƒê·ªçc d·ªØ li·ªáu
        data = self.load_comparison_data(json_file_path)
        if not data:
            return
        
        # L·ªçc engines c√≥ d·ªØ li·ªáu - ch·ªâ y√™u c·∫ßu time, kh√¥ng b·∫Øt bu·ªôc confidence/words cho t·∫•t c·∫£
        filtered_engines = {}
        for engine_key, engine_data in data.get('engines', {}).items():
            has_time = engine_data.get('avg_processing_time', 0) > 0 or engine_data.get('avg_time', 0) > 0
            if has_time:
                # Chu·∫©n h√≥a t√™n tr∆∞·ªùng
                normalized_data = dict(engine_data)
                if 'avg_time' in engine_data and 'avg_processing_time' not in engine_data:
                    normalized_data['avg_processing_time'] = engine_data['avg_time']
                if 'avg_words' in engine_data and 'avg_word_count' not in engine_data:
                    normalized_data['avg_word_count'] = engine_data['avg_words']
                filtered_engines[engine_key] = normalized_data
        
        if not filtered_engines:
            print("‚ùå Kh√¥ng c√≥ engine n√†o c√≥ d·ªØ li·ªáu th·ªùi gian ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì c·ªôt nh√≥m")
            return
        
        print(f"‚úÖ T√¨m th·∫•y {len(filtered_engines)} engines: {list(filtered_engines.keys())}")
        
        # Chu·∫©n b·ªã d·ªØ li·ªáu
        engine_names = []
        times = []
        word_counts = []
        confidences = []
        success_rates = []
        
        for engine_key, engine_data in filtered_engines.items():
            engine_names.append(engine_data.get('name', engine_key))
            times.append(engine_data.get('avg_processing_time', 0))
            word_counts.append(engine_data.get('avg_word_count', 0))
            confidences.append(engine_data.get('avg_confidence', 0))
            
            # T√≠nh success rate
            successful = engine_data.get('successful_runs', 0)
            total = successful + engine_data.get('failed_runs', 0)
            success_rate = (successful / total * 100) if total > 0 else 0
            success_rates.append(success_rate)
        
        # T·∫°o subplot v·ªõi 2x2 grid
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('üìä Ph√¢n T√≠ch Hi·ªáu Su·∫•t OCR - So S√°nh C√°c Th∆∞ Vi·ªán', fontsize=16, fontweight='bold')
        
        x = np.arange(len(engine_names))
        colors = [self.engine_colors.get(key, '#888888') for key in filtered_engines.keys()]
        
        # 1. Bi·ªÉu ƒë·ªì th·ªùi gian x·ª≠ l√Ω
        bars1 = ax1.bar(x, times, color=colors, alpha=0.8, edgecolor='black')
        ax1.set_xlabel('Th∆∞ vi·ªán OCR', fontweight='bold')
        ax1.set_ylabel('Th·ªùi gian (gi√¢y)', fontweight='bold')
        ax1.set_title('‚è±Ô∏è Th·ªùi Gian X·ª≠ L√Ω Trung B√¨nh')
        ax1.set_xticks(x)
        ax1.set_xticklabels(engine_names, rotation=45, ha='right')
        ax1.grid(True, alpha=0.3)
        
        # Th√™m gi√° tr·ªã tr√™n c·ªôt
        for bar, time_val in zip(bars1, times):
            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05,
                    f'{time_val:.2f}s', ha='center', va='bottom', fontweight='bold')
        
        # 2. Bi·ªÉu ƒë·ªì s·ªë t·ª´ nh·∫≠n di·ªán (ch·ªâ engines c√≥ word count > 0)
        valid_word_indices = [i for i, wc in enumerate(word_counts) if wc > 0]
        if valid_word_indices:
            valid_names = [engine_names[i] for i in valid_word_indices]
            valid_word_counts = [word_counts[i] for i in valid_word_indices]
            valid_colors = [colors[i] for i in valid_word_indices]
            
            x_words = np.arange(len(valid_names))
            bars2 = ax2.bar(x_words, valid_word_counts, color=valid_colors, alpha=0.8, edgecolor='black')
            ax2.set_xlabel('Th∆∞ vi·ªán OCR', fontweight='bold')
            ax2.set_ylabel('S·ªë t·ª´ trung b√¨nh', fontweight='bold')
            ax2.set_title('üìù S·ªë T·ª´ Nh·∫≠n Di·ªán Trung B√¨nh')
            ax2.set_xticks(x_words)
            ax2.set_xticklabels(valid_names, rotation=45, ha='right')
            ax2.grid(True, alpha=0.3)
            
            # Th√™m gi√° tr·ªã tr√™n c·ªôt
            for bar, word_val in zip(bars2, valid_word_counts):
                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                        f'{word_val:.1f}', ha='center', va='bottom', fontweight='bold')
        else:
            ax2.text(0.5, 0.5, 'Kh√¥ng c√≥ d·ªØ li·ªáu\ns·ªë t·ª´', ha='center', va='center', 
                    transform=ax2.transAxes, fontsize=12)
            ax2.set_title('üìù S·ªë T·ª´ Nh·∫≠n Di·ªán Trung B√¨nh')
        
        # 3. Bi·ªÉu ƒë·ªì ƒë·ªô ch√≠nh x√°c (ch·ªâ engines c√≥ confidence > 0)
        valid_conf_indices = [i for i, conf in enumerate(confidences) if conf > 0]
        if valid_conf_indices:
            valid_conf_names = [engine_names[i] for i in valid_conf_indices]
            valid_confidences = [confidences[i] for i in valid_conf_indices]
            valid_conf_colors = [colors[i] for i in valid_conf_indices]
            
            x_conf = np.arange(len(valid_conf_names))
            bars3 = ax3.bar(x_conf, valid_confidences, color=valid_conf_colors, alpha=0.8, edgecolor='black')
            ax3.set_xlabel('Th∆∞ vi·ªán OCR', fontweight='bold')
            ax3.set_ylabel('ƒê·ªô ch√≠nh x√°c (0-1)', fontweight='bold')
            ax3.set_title('üéØ ƒê·ªô Ch√≠nh X√°c Trung B√¨nh')
            ax3.set_xticks(x_conf)
            ax3.set_xticklabels(valid_conf_names, rotation=45, ha='right')
            ax3.set_ylim(0, 1)
            ax3.grid(True, alpha=0.3)
            
            # Th√™m gi√° tr·ªã tr√™n c·ªôt
            for bar, conf_val in zip(bars3, valid_confidences):
                ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,
                        f'{conf_val:.3f}', ha='center', va='bottom', fontweight='bold')
        else:
            ax3.text(0.5, 0.5, 'Kh√¥ng c√≥ d·ªØ li·ªáu\nƒë·ªô ch√≠nh x√°c', ha='center', va='center', 
                    transform=ax3.transAxes, fontsize=12)
            ax3.set_title('üéØ ƒê·ªô Ch√≠nh X√°c Trung B√¨nh')
        
        # 4. Bi·ªÉu ƒë·ªì t·ª∑ l·ªá th√†nh c√¥ng
        bars4 = ax4.bar(x, success_rates, color=colors, alpha=0.8, edgecolor='black')
        ax4.set_xlabel('Th∆∞ vi·ªán OCR', fontweight='bold')
        ax4.set_ylabel('T·ª∑ l·ªá th√†nh c√¥ng (%)', fontweight='bold')
        ax4.set_title('‚úÖ T·ª∑ L·ªá Th√†nh C√¥ng')
        ax4.set_xticks(x)
        ax4.set_xticklabels(engine_names, rotation=45, ha='right')
        ax4.set_ylim(0, 100)
        ax4.grid(True, alpha=0.3)
        
        # Th√™m gi√° tr·ªã tr√™n c·ªôt
        for bar, success_val in zip(bars4, success_rates):
            ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                    f'{success_val:.1f}%', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        
        # L∆∞u bi·ªÉu ƒë·ªì v√†o th∆∞ m·ª•c Charts
        output_path = os.path.join(self.charts_dir, f"{output_filename}.png")
        plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')
        plt.close()
        
        print(f"‚úÖ Bi·ªÉu ƒë·ªì c·ªôt nh√≥m ƒë√£ l∆∞u: {output_path}")
        return output_path
    
    def create_radar_chart_from_json(self, json_file_path, output_filename="radar_chart"):
        """T·∫°o bi·ªÉu ƒë·ªì radar t·ª´ file JSON"""
        print(f"üéØ T·∫°o bi·ªÉu ƒë·ªì radar t·ª´ {json_file_path}...")
        
        # ƒê·ªçc d·ªØ li·ªáu
        data = self.load_comparison_data(json_file_path)
        if not data:
            return
        
        # L·ªçc engines c√≥ d·ªØ li·ªáu
        filtered_engines = self.filter_engines_with_data(data, require_confidence=True, require_words=True)
        
        if not filtered_engines:
            print("‚ùå Kh√¥ng c√≥ engine n√†o c√≥ ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì radar")
            return
        
        # Chu·∫©n b·ªã d·ªØ li·ªáu
        categories = ['T·ªëc ƒë·ªô', 'S·ªë t·ª´', 'ƒê·ªô ch√≠nh x√°c', 'T·ª∑ l·ªá th√†nh c√¥ng']
        N = len(categories)
        
        # T√¨m gi√° tr·ªã max ƒë·ªÉ normalize
        max_time = max([engine_data.get('avg_processing_time', 0) for engine_data in filtered_engines.values()])
        max_words = max([engine_data.get('avg_word_count', 0) for engine_data in filtered_engines.values()])
        max_confidence = max([engine_data.get('avg_confidence', 0) for engine_data in filtered_engines.values()])
        
        # T·∫°o figure
        fig, ax = plt.subplots(figsize=(12, 10), subplot_kw=dict(projection='polar'))
        fig.suptitle('üéØ Bi·ªÉu ƒê·ªì Radar - So S√°nh To√†n Di·ªán C√°c Th∆∞ Vi·ªán OCR', fontsize=16, fontweight='bold')
        
        # G√≥c cho m·ªói tr·ª•c
        angles = [n / float(N) * 2 * pi for n in range(N)]
        angles += angles[:1]
        
        # V·∫Ω cho t·ª´ng engine
        for engine_key, engine_data in filtered_engines.items():
            # T√≠nh to√°n ƒëi·ªÉm s·ªë (0-1 scale)
            if max_time > 0:
                speed_score = 1 - (engine_data.get('avg_processing_time', 0) / max_time)  # ƒê·∫£o ng∆∞·ª£c: nhanh h∆°n = cao h∆°n
            else:
                speed_score = 1.0
                
            if max_words > 0:
                word_score = engine_data.get('avg_word_count', 0) / max_words
            else:
                word_score = 0.0
                
            if max_confidence > 0:
                confidence_score = engine_data.get('avg_confidence', 0) / max_confidence
            else:
                confidence_score = 0.0
            
            # T√≠nh success rate
            successful = engine_data.get('successful_runs', 0)
            total = successful + engine_data.get('failed_runs', 0)
            success_score = (successful / total) if total > 0 else 0
            
            values = [speed_score, word_score, confidence_score, success_score]
            values += values[:1]  # ƒê√≥ng v√≤ng tr√≤n
            
            color = self.engine_colors.get(engine_key, '#888888')
            label = engine_data.get('name', engine_key)
            
            ax.plot(angles, values, 'o-', linewidth=2, label=label, color=color)
            ax.fill(angles, values, alpha=0.25, color=color)
        
        # Thi·∫øt l·∫≠p tr·ª•c
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(categories, fontsize=12, fontweight='bold')
        ax.set_ylim(0, 1)
        
        # Thi·∫øt l·∫≠p grid
        ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])
        ax.set_yticklabels(['20%', '40%', '60%', '80%', '100%'], fontsize=10)
        ax.grid(True)
        
        # Legend
        plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0), fontsize=10)
        
        plt.tight_layout()
        
        # L∆∞u bi·ªÉu ƒë·ªì v√†o th∆∞ m·ª•c Charts
        output_path = os.path.join(self.charts_dir, f"{output_filename}.png")
        plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')
        plt.close()
        
        print(f"‚úÖ Bi·ªÉu ƒë·ªì radar ƒë√£ l∆∞u: {output_path}")
        return output_path
    
    def create_bubble_chart_from_json(self, json_file_path, output_filename="bubble_chart"):
        """T·∫°o bi·ªÉu ƒë·ªì bong b√≥ng t·ª´ file JSON"""
        print(f"üí´ T·∫°o bi·ªÉu ƒë·ªì bong b√≥ng t·ª´ {json_file_path}...")
        
        # ƒê·ªçc d·ªØ li·ªáu
        data = self.load_comparison_data(json_file_path)
        if not data:
            return
        
        # L·ªçc engines c√≥ d·ªØ li·ªáu (c·∫ßn c·∫£ confidence v√† words)
        filtered_engines = self.filter_engines_with_data(data, require_confidence=True, require_words=True)
        
        if not filtered_engines:
            print("‚ùå Kh√¥ng c√≥ engine n√†o c√≥ ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì bong b√≥ng")
            return
        
        # T·∫°o figure
        fig, ax = plt.subplots(figsize=(12, 8))
        fig.suptitle('üí´ Bi·ªÉu ƒê·ªì Bong B√≥ng - T·ªëc ƒê·ªô vs ƒê·ªô Ch√≠nh X√°c\n(K√≠ch th∆∞·ªõc bong b√≥ng = S·ªë t·ª´ nh·∫≠n di·ªán)', 
                     fontsize=14, fontweight='bold')
        
        # Chu·∫©n b·ªã d·ªØ li·ªáu
        x_values = []  # Th·ªùi gian x·ª≠ l√Ω
        y_values = []  # ƒê·ªô ch√≠nh x√°c
        sizes = []     # S·ªë t·ª´ (k√≠ch th∆∞·ªõc bong b√≥ng)
        colors = []
        labels = []
        
        for engine_key, engine_data in filtered_engines.items():
            x_values.append(engine_data.get('avg_processing_time', 0))
            y_values.append(engine_data.get('avg_confidence', 0))
            sizes.append(engine_data.get('avg_word_count', 0) * 20)  # Scale cho bubble size
            colors.append(self.engine_colors.get(engine_key, '#888888'))
            labels.append(engine_data.get('name', engine_key))
        
        # V·∫Ω bubbles
        scatter = ax.scatter(x_values, y_values, s=sizes, c=colors, alpha=0.6, edgecolors='black')
        
        # Th√™m labels cho t·ª´ng bubble
        for i, label in enumerate(labels):
            ax.annotate(label, (x_values[i], y_values[i]), 
                       xytext=(5, 5), textcoords='offset points',
                       fontsize=10, fontweight='bold',
                       bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.7))
        
        # Thi·∫øt l·∫≠p tr·ª•c
        ax.set_xlabel('‚è±Ô∏è Th·ªùi gian x·ª≠ l√Ω (gi√¢y)', fontsize=12, fontweight='bold')
        ax.set_ylabel('üéØ ƒê·ªô ch√≠nh x√°c', fontsize=12, fontweight='bold')
        ax.set_ylim(0, 1)
        ax.grid(True, alpha=0.3)
        
        # Th√™m ch√∫ th√≠ch v·ªÅ k√≠ch th∆∞·ªõc bubble
        word_counts = [engine_data.get('avg_word_count', 0) for engine_data in filtered_engines.values()]
        if word_counts:
            max_words = max(word_counts)
            min_words = min([w for w in word_counts if w > 0]) if any(w > 0 for w in word_counts) else 1
            
            # Legend cho bubble size
            legend_sizes = [min_words, max_words]
            legend_bubbles = []
            for size in legend_sizes:
                legend_bubbles.append(plt.scatter([], [], s=size*20, c='gray', alpha=0.6))
            
            legend1 = ax.legend(legend_bubbles, [f'{int(min_words)} t·ª´', f'{int(max_words)} t·ª´'], 
                               title="K√≠ch th∆∞·ªõc bong b√≥ng", loc='upper right', 
                               bbox_to_anchor=(1, 1))
            ax.add_artist(legend1)
        
        plt.tight_layout()
        
        # L∆∞u bi·ªÉu ƒë·ªì v√†o th∆∞ m·ª•c Charts
        output_path = os.path.join(self.charts_dir, f"{output_filename}.png")
        plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')
        plt.close()
        
        print(f"‚úÖ Bi·ªÉu ƒë·ªì bong b√≥ng ƒë√£ l∆∞u: {output_path}")
        return output_path
    
    def create_all_charts_from_json(self, json_file_path, output_prefix="ocr_analysis"):
        """T·∫°o t·∫•t c·∫£ bi·ªÉu ƒë·ªì t·ª´ file JSON"""
        print(f"üé® T·∫°o t·∫•t c·∫£ bi·ªÉu ƒë·ªì t·ª´ {json_file_path}...")
        
        results = {
            'grouped_bar': None,
            'radar': None,
            'bubble': None
        }
        
        try:
            # T·∫°o bi·ªÉu ƒë·ªì c·ªôt nh√≥m
            results['grouped_bar'] = self.create_grouped_bar_chart_from_json(
                json_file_path, f"{output_prefix}_grouped_bar"
            )
            
            # T·∫°o bi·ªÉu ƒë·ªì radar
            results['radar'] = self.create_radar_chart_from_json(
                json_file_path, f"{output_prefix}_radar"
            )
            
            # T·∫°o bi·ªÉu ƒë·ªì bong b√≥ng
            results['bubble'] = self.create_bubble_chart_from_json(
                json_file_path, f"{output_prefix}_bubble"
            )
            
            print(f"‚úÖ T·∫•t c·∫£ bi·ªÉu ƒë·ªì ƒë√£ ƒë∆∞·ª£c t·∫°o v·ªõi prefix: {output_prefix}")
            return results
            
        except Exception as e:
            print(f"‚ùå L·ªói t·∫°o bi·ªÉu ƒë·ªì: {str(e)}")
            import traceback
            traceback.print_exc()
            return results

def main():
    """Test function"""
    tool = JSONOCRVisualizationTool()
    
    # T√¨m file JSON comparison report m·ªõi nh·∫•t trong th∆∞ m·ª•c Json
    json_files = [f for f in os.listdir(tool.json_dir) if f.startswith('comparison_report_') and f.endswith('.json')]
    if not json_files:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file comparison report JSON trong {tool.json_dir}")
        return
    
    # S·ª≠ d·ª•ng file m·ªõi nh·∫•t
    latest_file = max([os.path.join(tool.json_dir, f) for f in json_files], key=os.path.getctime)
    latest_filename = os.path.basename(latest_file)
    print(f"üìÅ S·ª≠ d·ª•ng file: {latest_filename}")
    
    # T·∫°o t·∫•t c·∫£ bi·ªÉu ƒë·ªì
    results = tool.create_all_charts_from_json(latest_filename, "json_analysis")
    
    print("\nüéØ K·∫æT QU·∫¢:")
    for chart_type, file_path in results.items():
        if file_path:
            print(f"‚úÖ {chart_type}: {os.path.basename(file_path)}")
        else:
            print(f"‚ùå {chart_type}: Kh√¥ng t·∫°o ƒë∆∞·ª£c")

if __name__ == "__main__":
    main()